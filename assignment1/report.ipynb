{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f315860a",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"color: #4d2c6d;\">PROBLEM DEFINITON AND SOLUTION APROACH</h1>\n",
    "\n",
    "In first part, there is Personality Classification Dataset which contains 10000 samples with 60 attributes and 1 class label. We aim to classify different personality types of people using normal and weighted nearest neighbor algorithm with original and normalized dataset. In addition, we analyse our predictions using accuracy, precision and recall metrics.\n",
    "<br>\n",
    "In second part,there is Energy Efficiency Estimation Dataset which contains less than 1000 samples with 8 attributes and 2 class labels named Heating Load and Cooling Load. For this part, we again use normal and weighted nearest neighbor algorithm with original and normalized dataset. To analyse our predictions, we use Mean Absolute Error which is regression performance metric.\n",
    "<br><br>\n",
    "For both parts , since the Personality Classification Dataset contains too much samples and we calculate for 5 folds with 5 k-values for Normal and Weighted KNN for Non-Normalized and Normalized Data, it simply takes a long time for running. Since KNN algrithm uses distance arrays to predict the test samples , before running KNN algortihm, we calculated the distance arrays of all test samples for all 5-folds so that our running time 10 times faster. The algorithm is , for each test sample in test data, we calculate the euclidean distance between every training sample and test sample. While processing normal and weighted KNN , we just uses distance arrays to predict the test samples for 5 k-values in a very short time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adae163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBM409 Assignment 1 \n",
    "#b21946242 Numan Kafadar\n",
    "#b21946198 Umut Güngör\n",
    "\n",
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09e9dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fischer-yates algorithm to shuffle the dataset\n",
    "def shuffle(arr):\n",
    "    n=len(arr)\n",
    "    arr=arr.tolist()\n",
    "    for i in range(n-1,0,-1):\n",
    "        j = randint(0,i+1)\n",
    "        arr[i],arr[j] = arr[j],arr[i]\n",
    "    return np.asarray(arr)\n",
    "\n",
    "\n",
    "#normalization method for training dataset\n",
    "def normalization(data_set):\n",
    "    #geting min and max values of each columns\n",
    "    min_set = data_set.min(axis=0)\n",
    "    max_set = data_set.max(axis=0)\n",
    "    num_rows, num_cols = data_set.shape\n",
    "    \n",
    "    new_data_set = np.zeros((num_rows, num_cols)).astype(dtype=\"float64\")\n",
    "    \n",
    "    #min-max normalization\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            a1 = data_set[i, j] - min_set[j]\n",
    "            a2 = max_set[j] - min_set[j]\n",
    "            new_data_set[i, j] = a1 / a2\n",
    "    \n",
    "    return new_data_set\n",
    "\n",
    "#splitting data into 5 parts using kFold\n",
    "def kFold(data,labels,k=5):\n",
    "    size=len(data)\n",
    "    n=int(size/k)  #length of test samples\n",
    "    train_test_data=[]\n",
    "    \n",
    "    for i in range(k):\n",
    "        x_train=np.concatenate([data[:(i*n)],data[((i+1)*n):]])\n",
    "        x_test=np.concatenate([labels[:(i*n)],labels[((i+1)*n):]])\n",
    "        y_train=data[(i*n):((i+1)*n)]\n",
    "        y_test=labels[(i*n):((i+1)*n)]\n",
    "        train_test_data.append([x_train,x_test,y_train,y_test])\n",
    "        \n",
    "    return train_test_data\n",
    "\n",
    "#euclidean distance algorithm using numpy functions\n",
    "def fast_euclidean_distance(x,y):\n",
    "    return np.power(np.sum(np.power((x-y),2)),0.5,dtype=\"float64\")\n",
    "\n",
    "#calculating distance arrays for eacht test sample before KNN prediction\n",
    "def calculate_distances(train_data,test_data, labels):\n",
    "    result = []\n",
    "    for test_vector in test_data:\n",
    "        nearest_neighbors = []\n",
    "        idx = 0\n",
    "        for row in train_data:\n",
    "            dist = fast_euclidean_distance(test_vector, row)\n",
    "            nearest_neighbors.append((dist, labels[idx]))\n",
    "            idx += 1\n",
    "            \n",
    "        nearest_neighbors.sort(key=lambda t: t[0]) #sort the distances\n",
    "        result.append(nearest_neighbors)\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "#KNN algorithm for prediction\n",
    "def kNN(distances,k,kNNType=\"Normal\"):\n",
    "    predictions=[]\n",
    "    #weighted KNN\n",
    "    if kNNType==\"Weighted\":\n",
    "        for d in distances:\n",
    "            #get first k elements of the distance array\n",
    "            results = [row[1] for row in d[:k]] \n",
    "            dists=[row[0] for row in d[:k]] \n",
    "            neigs={}\n",
    "            \n",
    "            for i in range(len(results)):\n",
    "                #for each distance value, get its weight as 1/d\n",
    "                weight=1.0/dists[i]\n",
    "                if results[i] in neigs:\n",
    "                    neigs[results[i]]+=weight\n",
    "                else:\n",
    "                    neigs[results[i]]=weight\n",
    "            predictions.append(max(neigs, key=neigs.get))\n",
    "           \n",
    "    #normal KNN\n",
    "    else:\n",
    "        for d in distances:\n",
    "            #get first k elements of the distance array\n",
    "            results = [row[1] for row in d[:k]]\n",
    "            pred = max(set(results), key=results.count)\n",
    "            predictions.append(pred)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "#calculating accuracy, precision and recall metrics using confusion matrix\n",
    "def get_statics(actualVals, predVals ,classes): \n",
    "    #confusion matrix\n",
    "    conf_matrix = pd.DataFrame(\n",
    "    np.zeros((len(classes), len(classes)),dtype=int),\n",
    "                    index=classes, columns=classes)\n",
    "    for i, j in zip(actualVals ,predVals):\n",
    "        conf_matrix.loc[i, j] += 1\n",
    "    \n",
    "    #getting precision and recall using confusion matrix\n",
    "    precision,recall=calculate_metrics(conf_matrix.to_numpy())\n",
    "\n",
    "    #calculating accuracy\n",
    "    correct = 0\n",
    "    for i in range(len(actualVals)):\n",
    "        if actualVals[i] == predVals[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    accuracy=correct / float(len(actualVals)) \n",
    "\n",
    "    return accuracy*100, precision*100, recall*100\n",
    "\n",
    "# a method for getting precision and recall metrics using confusion matrix\n",
    "def calculate_metrics(metrics_matrix):\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    for i in range(16):\n",
    "        precision += metrics_matrix[i, i] / np.sum(metrics_matrix[i])\n",
    "        recall += metrics_matrix[i, i] / np.sum(metrics_matrix[:, i])\n",
    "        \n",
    "    precision /= 16\n",
    "    recall /= 16\n",
    "    \n",
    "    return  precision , recall\n",
    "\n",
    "\n",
    "#Mean Absolute Error calculation method\n",
    "def mae(actuals ,preds):\n",
    "    dif=0.0\n",
    "    for i in range(len(actuals)):\n",
    "        dif+=abs(actuals[i]-preds[i])\n",
    "    return dif/len(actuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to get misclassified items to comment why they are misclassified \n",
    "\"\"\"\n",
    "def get_misclassified_items(test_data,actuals,preds):\n",
    "    res=[]\n",
    "    for i in range(len(actuals)):\n",
    "        if actuals[i] != preds[i]:\n",
    "            res.append([test_data[i],actuals[i],preds[i]])\n",
    "    return res\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62be03ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response Id</th>\n",
       "      <th>You regularly make new friends.</th>\n",
       "      <th>You spend a lot of your free time exploring various random topics that pique your interest</th>\n",
       "      <th>Seeing other people cry can easily make you feel like you want to cry too</th>\n",
       "      <th>You often make a backup plan for a backup plan.</th>\n",
       "      <th>You usually stay calm, even under a lot of pressure</th>\n",
       "      <th>At social events, you rarely try to introduce yourself to new people and mostly talk to the ones you already know</th>\n",
       "      <th>You prefer to completely finish one project before starting another.</th>\n",
       "      <th>You are very sentimental.</th>\n",
       "      <th>You like to use organizing tools like schedules and lists.</th>\n",
       "      <th>...</th>\n",
       "      <th>You believe that pondering abstract philosophical questions is a waste of time.</th>\n",
       "      <th>You feel more drawn to places with busy, bustling atmospheres than quiet, intimate places.</th>\n",
       "      <th>You know at first glance how someone is feeling.</th>\n",
       "      <th>You often feel overwhelmed.</th>\n",
       "      <th>You complete things methodically without skipping over any steps.</th>\n",
       "      <th>You are very intrigued by things labeled as controversial.</th>\n",
       "      <th>You would pass along a good opportunity if you thought someone else needed it more.</th>\n",
       "      <th>You struggle with deadlines.</th>\n",
       "      <th>You feel confident that things will work out for you.</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35874</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>ENTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ESTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>ENTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Response Id  You regularly make new friends.  \\\n",
       "0        35874                               -1   \n",
       "1        42624                                0   \n",
       "2        55199                                0   \n",
       "3        52983                                0   \n",
       "4        22864                                0   \n",
       "\n",
       "   You spend a lot of your free time exploring various random topics that pique your interest  \\\n",
       "0                                                  0                                            \n",
       "1                                                  0                                            \n",
       "2                                                  0                                            \n",
       "3                                                  0                                            \n",
       "4                                                  0                                            \n",
       "\n",
       "   Seeing other people cry can easily make you feel like you want to cry too  \\\n",
       "0                                                 -1                           \n",
       "1                                                  1                           \n",
       "2                                                 -2                           \n",
       "3                                                  0                           \n",
       "4                                                  2                           \n",
       "\n",
       "   You often make a backup plan for a backup plan.  \\\n",
       "0                                                1   \n",
       "1                                                0   \n",
       "2                                               -1   \n",
       "3                                                1   \n",
       "4                                                1   \n",
       "\n",
       "   You usually stay calm, even under a lot of pressure  \\\n",
       "0                                                 -1     \n",
       "1                                                  0     \n",
       "2                                                  2     \n",
       "3                                                 -2     \n",
       "4                                                  0     \n",
       "\n",
       "   At social events, you rarely try to introduce yourself to new people and mostly talk to the ones you already know  \\\n",
       "0                                                 -2                                                                   \n",
       "1                                                  0                                                                   \n",
       "2                                                 -2                                                                   \n",
       "3                                                 -1                                                                   \n",
       "4                                                 -2                                                                   \n",
       "\n",
       "   You prefer to completely finish one project before starting another.  \\\n",
       "0                                                 -2                      \n",
       "1                                                 -1                      \n",
       "2                                                  0                      \n",
       "3                                                  0                      \n",
       "4                                                 -1                      \n",
       "\n",
       "   You are very sentimental.  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "   You like to use organizing tools like schedules and lists.  ...  \\\n",
       "0                                                 -1           ...   \n",
       "1                                                  0           ...   \n",
       "2                                                 -1           ...   \n",
       "3                                                  1           ...   \n",
       "4                                                  1           ...   \n",
       "\n",
       "   You believe that pondering abstract philosophical questions is a waste of time.  \\\n",
       "0                                                  0                                 \n",
       "1                                                  0                                 \n",
       "2                                                  0                                 \n",
       "3                                                  1                                 \n",
       "4                                                  1                                 \n",
       "\n",
       "   You feel more drawn to places with busy, bustling atmospheres than quiet, intimate places.  \\\n",
       "0                                                  3                                            \n",
       "1                                                  2                                            \n",
       "2                                                  0                                            \n",
       "3                                                  1                                            \n",
       "4                                                 -2                                            \n",
       "\n",
       "   You know at first glance how someone is feeling.  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   You often feel overwhelmed.  \\\n",
       "0                            0   \n",
       "1                            0   \n",
       "2                            1   \n",
       "3                           -1   \n",
       "4                            1   \n",
       "\n",
       "   You complete things methodically without skipping over any steps.  \\\n",
       "0                                                  0                   \n",
       "1                                                  0                   \n",
       "2                                                  0                   \n",
       "3                                                  0                   \n",
       "4                                                  0                   \n",
       "\n",
       "   You are very intrigued by things labeled as controversial.  \\\n",
       "0                                                  0            \n",
       "1                                                  0            \n",
       "2                                                  0            \n",
       "3                                                 -1            \n",
       "4                                                  0            \n",
       "\n",
       "   You would pass along a good opportunity if you thought someone else needed it more.  \\\n",
       "0                                                  1                                     \n",
       "1                                                 -1                                     \n",
       "2                                                  3                                     \n",
       "3                                                  2                                     \n",
       "4                                                  0                                     \n",
       "\n",
       "   You struggle with deadlines.  \\\n",
       "0                            -1   \n",
       "1                            -3   \n",
       "2                             0   \n",
       "3                            -2   \n",
       "4                            -2   \n",
       "\n",
       "   You feel confident that things will work out for you.  Personality  \n",
       "0                                                  0             ENTP  \n",
       "1                                                  2             INTP  \n",
       "2                                                  0             ESTP  \n",
       "3                                                  0             ENTP  \n",
       "4                                                  2             ENFJ  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data exploring\n",
    "df = pd.read_csv(\"subset_16P.csv\", encoding=\"cp1252\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bfcc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(df)\n",
    "\n",
    "#shuffle the numpy array\n",
    "arr=shuffle(arr)\n",
    "\n",
    "#splitting labels and features\n",
    "x = arr[:, 1:-1].astype(dtype=\"int32\")\n",
    "y = arr[:, -1:]\n",
    "y = y.reshape(len(y),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c14242da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Normalized Data ,Getting Distance arrays...\n",
      "For fold 1 , prediction time = 127.39372944831848 \n",
      "For fold 2 , prediction time = 127.56444835662842 \n",
      "For fold 3 , prediction time = 127.68071365356445 \n",
      "For fold 4 , prediction time = 131.48431587219238 \n",
      "For fold 5 , prediction time = 129.12363290786743 \n"
     ]
    }
   ],
   "source": [
    "#split the data into 5 fold\n",
    "folds=kFold(x,y)\n",
    "\n",
    "#First , getting all the distance arrays to process KNN\n",
    "foldsResult=[]\n",
    "fnum=1\n",
    "print(\"Non-Normalized Data ,Getting Distance arrays...\")\n",
    "for fold in folds:\n",
    "    st=time.time()\n",
    "    dist=calculate_distances(fold[0],fold[2],fold[1])\n",
    "    et=time.time()\n",
    "    passed=et-st\n",
    "    print(\"For fold {} , prediction time = {} \".format(fnum,passed))\n",
    "    foldsResult.append(dist)\n",
    "    fnum+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "56d46a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class list for part 1\n",
    "classes=df[\"Personality\"].unique()\n",
    "\n",
    "\n",
    "#Average of 5-fold Cross Validation Results\n",
    "def get_Avrgs(arr,n):\n",
    "    res=[]\n",
    "    #calculating each folds average results\n",
    "    for i in range(5):\n",
    "        tmp=[0.0]*n\n",
    "        for k in range(n):\n",
    "            for j in range(5): \n",
    "                tmp[k]+=arr[j][i][k]\n",
    "        res.append(tmp)\n",
    "        \n",
    "    for i in range(5):\n",
    "        for j in range(n):\n",
    "            res[i][j]=round(res[i][j]/5,3)\n",
    "    rN=[]\n",
    "    rW=[]\n",
    "    \n",
    "    #getting values in table format for jupyter markdown\n",
    "    for i in range(5):\n",
    "        rN.append(\"Accuracy : %\"+str(res[i][0])+\"<br> Precision : %\"+str(res[i][1])+\n",
    "                      \"<br> Recall : %\"+str(res[i][2]))\n",
    "        rW.append(\"Accuracy : %\"+str(res[i][3])+\"<br> Precision : %\"+str(res[i][4])+\n",
    "                      \"<br> Recall : %\"+str(res[i][5]))\n",
    "    #return normal averages and weighted averages of each folds\n",
    "    return rN,rW\n",
    "\n",
    "\n",
    "#processing KNN for each k value and each fold \n",
    "#this function simply returns pandas Dataframe of average,precision and recall metrics table\n",
    "#for both normal and weighted KNN\n",
    "def get_KNN_Table_pt1(fold_result,folds):\n",
    "    kArray=[1,3,5,7,9]\n",
    "    fnum=1\n",
    "    avrgNonNormalizd=[]\n",
    "    resaN=[]\n",
    "    resaW=[]\n",
    "    for dists in fold_result:\n",
    "        tmp=[]\n",
    "        aN=[]\n",
    "        aW=[]\n",
    "        for k in kArray:\n",
    "            predsNormal=kNN(dists,k)\n",
    "            predsWeighted=kNN(dists,k,kNNType=\"Weighted\")\n",
    "            accuracyN, precisionN, recallN=get_statics(folds[fnum-1][3],predsNormal,classes)\n",
    "            accuracyW, precisionW, recallW=get_statics(folds[fnum-1][3],predsWeighted,classes)\n",
    "            aN.append(\"Accuracy : %\"+str(round(accuracyN,3))+\"<br> Precision : %\"+str(round(precisionN,3))+\n",
    "                      \"<br> Recall : %\"+str(round(recallN,3)))\n",
    "            aW.append(\"Accuracy : %\"+str(round(accuracyW,3))+\"<br> Precision : %\"+str(round(precisionW,3))+\n",
    "                      \"<br> Recall : %\"+str(round(recallW,3)))\n",
    "            tmp.append([accuracyN,precisionN,recallN,accuracyW,precisionW,recallW])\n",
    "        avrgNonNormalizd.append(tmp)\n",
    "        fnum+=1\n",
    "        resaN.append(aN)\n",
    "        resaW.append(aW)\n",
    "        \n",
    "    avrN,avrW=get_Avrgs(avrgNonNormalizd.copy(),6)\n",
    "    resaN.append(avrN)\n",
    "    resaW.append(avrW)\n",
    "    \n",
    "    #normal KNN Results as Dataframe\n",
    "    df1=pd.DataFrame(resaN,index=[\"Fold 1\",\"Fold 2\",\"Fold 3\",\"Fold 4\",\"Fold 5\",\"Average Of The Folds\"],\n",
    "                       columns=[\"k=1\",\"k=3\",\"k=5\",\"k=7\",\"k=9\"])\n",
    "    \n",
    "    #Weighted KNN Results as Dataframe\n",
    "    df2=pd.DataFrame(resaW,index=[\"Fold 1\",\"Fold 2\",\"Fold 3\",\"Fold 4\",\"Fold 5\",\"Average Of The Folds\"],columns=[\"k=1\",\"k=3\",\"k=5\",\"k=7\",\"k=9\"])\n",
    "    return df1,df2\n",
    "                     \n",
    "#getting results of KNN for Non-Normalized Data\n",
    "df_normal,df_weighted=get_KNN_Table_pt1(foldsResult,folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "735e80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing Non-Normalized and Non-Weighted KNN for report\n",
    "#print(df_normal.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4eacba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing Non-Normalized and Weighted KNN for report\n",
    "#print(df_weighted.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "219b7935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data ,Getting Distance arrays...\n",
      "For fold 1 , prediction time = 151.71541738510132 \n",
      "For fold 2 , prediction time = 147.46635460853577 \n",
      "For fold 3 , prediction time = 148.93905568122864 \n",
      "For fold 4 , prediction time = 146.65138053894043 \n",
      "For fold 5 , prediction time = 148.01044344902039 \n"
     ]
    }
   ],
   "source": [
    "normalized_x=normalization(x) #normalize the train set\n",
    "foldsNormalized=kFold(normalized_x,y)\n",
    "#First , getting all the distance arrays to process KNN\n",
    "foldsResultNormalized=[]\n",
    "fnum=1\n",
    "print(\"Normalized Data ,Getting Distance arrays...\")\n",
    "for fold in foldsNormalized:\n",
    "    st=time.time()\n",
    "    dist=calculate_distances(fold[0],fold[2],fold[1])\n",
    "    et=time.time()\n",
    "    passed=et-st\n",
    "    print(\"For fold {} , prediction time = {} \".format(fnum,passed))\n",
    "    foldsResultNormalized.append(dist)\n",
    "    fnum+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e4e783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting results of KNN for Normalized Data\n",
    "normalized_df_normal,normalized_df_weighted=get_KNN_Table_pt1(foldsResultNormalized,foldsNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5d84b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing Normalized and Non-Weighted KNN for report as markdown table\n",
    "#print(normalized_df_normal.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9988e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing Normalized and Weighted KNN for report as markdown table\n",
    "#print(normalized_df_weighted.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396093f",
   "metadata": {},
   "source": [
    "<h1 style=\"text-transform: uppercase;\n",
    "           font-size:40px;\n",
    "           color: #4d2c6d;\n",
    "            \">PART 1: Personality Classification</h1>\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table For Non-normalized and Non-Weighted Data</h3>\n",
    "           \n",
    "|                      | k=1                                                            | k=3                                                            | k=5                                                            | k=7                                                            | k=9                                                            |\n",
    "|:---------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|\n",
    "| Fold 1               | Accuracy : %97.45<br> Precision : %97.486<br> Recall : %97.461 | Accuracy : %98.4<br> Precision : %98.403<br> Recall : %98.426  | Accuracy : %98.65<br> Precision : %98.642<br> Recall : %98.662 | Accuracy : %98.6<br> Precision : %98.596<br> Recall : %98.616  | Accuracy : %98.45<br> Precision : %98.444<br> Recall : %98.468 |\n",
    "| Fold 2               | Accuracy : %97.35<br> Precision : %97.374<br> Recall : %97.367 | Accuracy : %98.15<br> Precision : %98.176<br> Recall : %98.139 | Accuracy : %98.6<br> Precision : %98.615<br> Recall : %98.622  | Accuracy : %98.6<br> Precision : %98.606<br> Recall : %98.62   | Accuracy : %98.55<br> Precision : %98.556<br> Recall : %98.574 |\n",
    "| Fold 3               | Accuracy : %97.75<br> Precision : %97.765<br> Recall : %97.787 | Accuracy : %98.7<br> Precision : %98.699<br> Recall : %98.708  | Accuracy : %98.95<br> Precision : %98.939<br> Recall : %98.956 | Accuracy : %98.95<br> Precision : %98.941<br> Recall : %98.966 | Accuracy : %98.95<br> Precision : %98.941<br> Recall : %98.966 |\n",
    "| Fold 4               | Accuracy : %97.4<br> Precision : %97.454<br> Recall : %97.391  | Accuracy : %98.55<br> Precision : %98.595<br> Recall : %98.536 | Accuracy : %98.65<br> Precision : %98.699<br> Recall : %98.633 | Accuracy : %98.8<br> Precision : %98.839<br> Recall : %98.783  | Accuracy : %98.9<br> Precision : %98.94<br> Recall : %98.882   |\n",
    "| Fold 5               | Accuracy : %97.35<br> Precision : %97.38<br> Recall : %97.375  | Accuracy : %98.4<br> Precision : %98.376<br> Recall : %98.396  | Accuracy : %98.85<br> Precision : %98.821<br> Recall : %98.845 | Accuracy : %98.8<br> Precision : %98.773<br> Recall : %98.802  | Accuracy : %98.9<br> Precision : %98.888<br> Recall : %98.894  |\n",
    "| Average Of The Folds | Accuracy : %97.46<br> Precision : %97.492<br> Recall : %97.476 | Accuracy : %98.44<br> Precision : %98.45<br> Recall : %98.441  | Accuracy : %98.74<br> Precision : %98.743<br> Recall : %98.744 | Accuracy : %98.75<br> Precision : %98.751<br> Recall : %98.758 | Accuracy : %98.75<br> Precision : %98.754<br> Recall : %98.757 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table For Non-normalized and Weighted Data</h3>\n",
    "           \n",
    "|                      | k=1                                                            | k=3                                                            | k=5                                                            | k=7                                                            | k=9                                                            |\n",
    "|:---------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|\n",
    "| Fold 1               | Accuracy : %97.45<br> Precision : %97.486<br> Recall : %97.461 | Accuracy : %98.45<br> Precision : %98.451<br> Recall : %98.47  | Accuracy : %98.6<br> Precision : %98.591<br> Recall : %98.622  | Accuracy : %98.65<br> Precision : %98.646<br> Recall : %98.663 | Accuracy : %98.6<br> Precision : %98.593<br> Recall : %98.617  |\n",
    "| Fold 2               | Accuracy : %97.35<br> Precision : %97.374<br> Recall : %97.367 | Accuracy : %98.25<br> Precision : %98.279<br> Recall : %98.262 | Accuracy : %98.6<br> Precision : %98.615<br> Recall : %98.625  | Accuracy : %98.6<br> Precision : %98.606<br> Recall : %98.627  | Accuracy : %98.6<br> Precision : %98.606<br> Recall : %98.624  |\n",
    "| Fold 3               | Accuracy : %97.75<br> Precision : %97.765<br> Recall : %97.787 | Accuracy : %98.85<br> Precision : %98.838<br> Recall : %98.868 | Accuracy : %98.95<br> Precision : %98.939<br> Recall : %98.956 | Accuracy : %98.9<br> Precision : %98.882<br> Recall : %98.919  | Accuracy : %98.95<br> Precision : %98.941<br> Recall : %98.966 |\n",
    "| Fold 4               | Accuracy : %97.4<br> Precision : %97.454<br> Recall : %97.391  | Accuracy : %98.75<br> Precision : %98.791<br> Recall : %98.734 | Accuracy : %98.8<br> Precision : %98.845<br> Recall : %98.782  | Accuracy : %98.85<br> Precision : %98.888<br> Recall : %98.831 | Accuracy : %98.9<br> Precision : %98.942<br> Recall : %98.882  |\n",
    "| Fold 5               | Accuracy : %97.35<br> Precision : %97.38<br> Recall : %97.375  | Accuracy : %98.5<br> Precision : %98.487<br> Recall : %98.502  | Accuracy : %98.8<br> Precision : %98.779<br> Recall : %98.795  | Accuracy : %98.8<br> Precision : %98.773<br> Recall : %98.802  | Accuracy : %98.9<br> Precision : %98.888<br> Recall : %98.894  |\n",
    "| Average Of The Folds | Accuracy : %97.46<br> Precision : %97.492<br> Recall : %97.476 | Accuracy : %98.56<br> Precision : %98.569<br> Recall : %98.567 | Accuracy : %98.75<br> Precision : %98.754<br> Recall : %98.756 | Accuracy : %98.76<br> Precision : %98.759<br> Recall : %98.768 | Accuracy : %98.79<br> Precision : %98.794<br> Recall : %98.796 |\n",
    "\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table For Normalized and Non-Weighted Data</h3>\n",
    "\n",
    "\n",
    "|                      | k=1                                                            | k=3                                                            | k=5                                                            | k=7                                                            | k=9                                                            |\n",
    "|:---------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|\n",
    "| Fold 1               | Accuracy : %96.0<br> Precision : %96.063<br> Recall : %96.01   | Accuracy : %97.6<br> Precision : %97.614<br> Recall : %97.58   | Accuracy : %98.15<br> Precision : %98.158<br> Recall : %98.133 | Accuracy : %98.4<br> Precision : %98.407<br> Recall : %98.428  | Accuracy : %98.2<br> Precision : %98.211<br> Recall : %98.228  |\n",
    "| Fold 2               | Accuracy : %96.15<br> Precision : %96.139<br> Recall : %96.155 | Accuracy : %97.75<br> Precision : %97.783<br> Recall : %97.764 | Accuracy : %98.05<br> Precision : %98.056<br> Recall : %98.069 | Accuracy : %98.25<br> Precision : %98.251<br> Recall : %98.269 | Accuracy : %98.5<br> Precision : %98.499<br> Recall : %98.523  |\n",
    "| Fold 3               | Accuracy : %96.45<br> Precision : %96.439<br> Recall : %96.401 | Accuracy : %97.95<br> Precision : %97.969<br> Recall : %97.948 | Accuracy : %98.6<br> Precision : %98.596<br> Recall : %98.625  | Accuracy : %98.8<br> Precision : %98.808<br> Recall : %98.811  | Accuracy : %98.6<br> Precision : %98.61<br> Recall : %98.616   |\n",
    "| Fold 4               | Accuracy : %96.5<br> Precision : %96.596<br> Recall : %96.505  | Accuracy : %97.8<br> Precision : %97.871<br> Recall : %97.782  | Accuracy : %98.25<br> Precision : %98.311<br> Recall : %98.227 | Accuracy : %98.4<br> Precision : %98.468<br> Recall : %98.379  | Accuracy : %98.55<br> Precision : %98.601<br> Recall : %98.532 |\n",
    "| Fold 5               | Accuracy : %95.75<br> Precision : %95.721<br> Recall : %95.822 | Accuracy : %97.75<br> Precision : %97.704<br> Recall : %97.765 | Accuracy : %98.3<br> Precision : %98.27<br> Recall : %98.295   | Accuracy : %98.4<br> Precision : %98.376<br> Recall : %98.391  | Accuracy : %98.35<br> Precision : %98.332<br> Recall : %98.36  |\n",
    "| Average Of The Folds | Accuracy : %96.17<br> Precision : %96.192<br> Recall : %96.179 | Accuracy : %97.77<br> Precision : %97.788<br> Recall : %97.768 | Accuracy : %98.27<br> Precision : %98.278<br> Recall : %98.27  | Accuracy : %98.45<br> Precision : %98.462<br> Recall : %98.456 | Accuracy : %98.44<br> Precision : %98.451<br> Recall : %98.452 |\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table For Normalized and Weighted Data</h3>\n",
    "\n",
    "|                      | k=1                                                            | k=3                                                            | k=5                                                            | k=7                                                            | k=9                                                            |\n",
    "|:---------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|:---------------------------------------------------------------|\n",
    "| Fold 1               | Accuracy : %96.0<br> Precision : %96.063<br> Recall : %96.01   | Accuracy : %97.75<br> Precision : %97.77<br> Recall : %97.721  | Accuracy : %98.2<br> Precision : %98.215<br> Recall : %98.197  | Accuracy : %98.45<br> Precision : %98.456<br> Recall : %98.465 | Accuracy : %98.15<br> Precision : %98.165<br> Recall : %98.166 |\n",
    "| Fold 2               | Accuracy : %96.15<br> Precision : %96.139<br> Recall : %96.155 | Accuracy : %98.0<br> Precision : %98.016<br> Recall : %98.016  | Accuracy : %98.2<br> Precision : %98.215<br> Recall : %98.225  | Accuracy : %98.3<br> Precision : %98.301<br> Recall : %98.313  | Accuracy : %98.5<br> Precision : %98.499<br> Recall : %98.523  |\n",
    "| Fold 3               | Accuracy : %96.45<br> Precision : %96.439<br> Recall : %96.401 | Accuracy : %98.1<br> Precision : %98.093<br> Recall : %98.085  | Accuracy : %98.55<br> Precision : %98.553<br> Recall : %98.578 | Accuracy : %98.8<br> Precision : %98.808<br> Recall : %98.818  | Accuracy : %98.75<br> Precision : %98.757<br> Recall : %98.769 |\n",
    "| Fold 4               | Accuracy : %96.5<br> Precision : %96.596<br> Recall : %96.505  | Accuracy : %97.8<br> Precision : %97.862<br> Recall : %97.767  | Accuracy : %98.35<br> Precision : %98.405<br> Recall : %98.322 | Accuracy : %98.55<br> Precision : %98.609<br> Recall : %98.527 | Accuracy : %98.55<br> Precision : %98.61<br> Recall : %98.524  |\n",
    "| Fold 5               | Accuracy : %95.75<br> Precision : %95.721<br> Recall : %95.822 | Accuracy : %98.05<br> Precision : %98.007<br> Recall : %98.054 | Accuracy : %98.45<br> Precision : %98.412<br> Recall : %98.442 | Accuracy : %98.55<br> Precision : %98.522<br> Recall : %98.554 | Accuracy : %98.55<br> Precision : %98.529<br> Recall : %98.536 |\n",
    "| Average Of The Folds | Accuracy : %96.17<br> Precision : %96.192<br> Recall : %96.179 | Accuracy : %97.94<br> Precision : %97.95<br> Recall : %97.929  | Accuracy : %98.35<br> Precision : %98.36<br> Recall : %98.353  | Accuracy : %98.53<br> Precision : %98.539<br> Recall : %98.535 | Accuracy : %98.5<br> Precision : %98.512<br> Recall : %98.503  |\n",
    "\n",
    "<h1 style=\"color: #4d2c6d;\">Error Analysis for Classification</h1>\n",
    "<ul>\n",
    "  <li><p> When we run the KNN algorithm, we notice that there are some samples which are misclassified. For instance, labels of some samples predicted as \"ESTJ\"(The Supervisor) but their actual labels are \"ESFJ\"(The Provider). One of the reasons of this misclassification can be that attributes of these classes are very close to each other. In dataset, there are some samples which are labeled as \"ESTJ\" or \"ESFJ\" and their attribute values are quite similar. This causes misclassification. Another reason for misclassification is that there are some samples whose labels are same but their attributes are very different. These differences make it difficult to find the correct label. Also, there are notable number of misclassified samples for \"INTP\"(The Thinker) and \"INFP\"(The Idealist). Actually, most of the misclassified samples' labels are relatively close to each other like \"ESTJ\"(The Supervisor) and \"ESFJ\"(The Provider).</p>\n",
    "</li>\n",
    "  <li><p> The accuracy of the model decreases, if we use fewer training samples. Because, when the number of training samples increase, the model is well-trained. So, number of training samples are important for training. The accuracy of the model increases as the number of training samples are increases if training samples are randomly distributed. There is another factor that affects accuracy of the model which is k-value of KNN algorithm. When we examine the results of the KNN algorithms from the tables, we can see that since the accuracy, precision and recall metrics are slightly increasing with k-value, the performance of the model increases proportionally with k-value. However, there are some exceptions at some k-values. Accuracy of the model is higher when we use weighted KNN algorithm rather than normal KNN algorithm. Also, normalization is another parameter that affects accuracy. In this problem, normalization is inversely proportional with accuracy of the model. </p>\n",
    "</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "361b78dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative_Compactness</th>\n",
       "      <th>Surface_Area</th>\n",
       "      <th>Wall_Area</th>\n",
       "      <th>Roof_Area</th>\n",
       "      <th>Overall_Height</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Glazing_Area</th>\n",
       "      <th>Glazing_Area_Distribution</th>\n",
       "      <th>Heating_Load</th>\n",
       "      <th>Cooling_Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Relative_Compactness  Surface_Area  Wall_Area  Roof_Area  Overall_Height  \\\n",
       "0                  0.98         514.5      294.0     110.25             7.0   \n",
       "1                  0.98         514.5      294.0     110.25             7.0   \n",
       "2                  0.98         514.5      294.0     110.25             7.0   \n",
       "3                  0.98         514.5      294.0     110.25             7.0   \n",
       "4                  0.90         563.5      318.5     122.50             7.0   \n",
       "\n",
       "   Orientation  Glazing_Area  Glazing_Area_Distribution  Heating_Load  \\\n",
       "0            2           0.0                          0         15.55   \n",
       "1            3           0.0                          0         15.55   \n",
       "2            4           0.0                          0         15.55   \n",
       "3            5           0.0                          0         15.55   \n",
       "4            2           0.0                          0         20.84   \n",
       "\n",
       "   Cooling_Load  \n",
       "0         21.33  \n",
       "1         21.33  \n",
       "2         21.33  \n",
       "3         21.33  \n",
       "4         28.28  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data exploring \n",
    "df2=pd.read_csv(\"energy_efficiency_data.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75d7fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2 = np.array(df2).astype(dtype=\"float64\")\n",
    "\n",
    "arr_2=shuffle(arr_2) #shuffling the array\n",
    "x_values = arr_2[:, :-2]\n",
    "\n",
    "#normalized feature values\n",
    "normalized_x_values=normalization(x_values)\n",
    "\n",
    "y_heating_load = arr_2[:, -2:-1]\n",
    "y_cooling_load = arr_2[:, -1:]\n",
    "y_heating_load = y_heating_load.reshape(len(y_heating_load),)\n",
    "y_cooling_load = y_cooling_load.reshape(len(y_cooling_load),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9701a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold cross validation \n",
    "folds_heating=kFold(x_values,y_heating_load)\n",
    "folds_cooling=kFold(x_values,y_cooling_load)\n",
    "folds_heating_normalized=kFold(normalized_x_values,y_heating_load)\n",
    "folds_cooling_normalized=kFold(normalized_x_values,y_cooling_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50ab72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN regression algorithm for part 2\n",
    "def kNN_for_Regression(distances,k,kNNType=\"Normal\"):\n",
    "    predictions=[]\n",
    "    #weighted KNN\n",
    "    if kNNType==\"Weighted\":\n",
    "        \n",
    "        for d in distances:\n",
    "            #get first k elements of the distance array\n",
    "            results = [row[1] for row in d[:k]] \n",
    "            dists=[row[0] for row in d[:k]] \n",
    "            neigs={}\n",
    "            \n",
    "            pred=0.0 \n",
    "            weight_sum=0.0 #sum of k weightes\n",
    "            for i in range(len(results)):\n",
    "                #for each distance value, get its weight as 1/d\n",
    "                weight=1.0/dists[i] \n",
    "                weight_sum+=weight\n",
    "                #for each closest sample, sum up pred value with weight * samples label value\n",
    "                pred+=weight*results[i] \n",
    "            \n",
    "            #our prediction\n",
    "            pred=pred/weight_sum \n",
    "            predictions.append(pred)\n",
    "           \n",
    "    #normal KNN\n",
    "    else:\n",
    "        for d in distances:\n",
    "            #get first k elements of the distance array\n",
    "            results = [row[1] for row in d[:k]]\n",
    "            #getting average of the closest sample labels \n",
    "            pred=float(sum(results)/k)\n",
    "            predictions.append(pred)\n",
    "\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5cd8e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-normalized Data ,Getting Distance Arrays......\n",
      "For fold 1 , prediction time = 0.7201764583587646 \n",
      "For fold 2 , prediction time = 0.7227578163146973 \n",
      "For fold 3 , prediction time = 0.7140519618988037 \n",
      "For fold 4 , prediction time = 0.7194526195526123 \n",
      "For fold 5 , prediction time = 0.7174234390258789 \n",
      "Normalized Data ,Getting Distance Arrays...\n",
      "For fold 1 , prediction time = 0.7194654941558838 \n",
      "For fold 2 , prediction time = 0.7171614170074463 \n",
      "For fold 3 , prediction time = 0.7224252223968506 \n",
      "For fold 4 , prediction time = 0.7191641330718994 \n",
      "For fold 5 , prediction time = 0.7173745632171631 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calculating distance arrays for Heating Load\n",
    "folds_heating_result=[]\n",
    "fnum=1\n",
    "print(\"Non-normalized Data ,Getting Distance Arrays......\")\n",
    "for fold in folds_heating:\n",
    "    st=time.time()\n",
    "    dist=calculate_distances(fold[0],fold[2],fold[1])\n",
    "    et=time.time()\n",
    "    passed=et-st\n",
    "    print(\"For fold {} , prediction time = {} \".format(fnum,passed))\n",
    "    folds_heating_result.append(dist)\n",
    "    fnum+=1\n",
    "\n",
    "folds_heating_result_normalized=[]\n",
    "fnum=1\n",
    "print(\"Normalized Data ,Getting Distance Arrays...\")\n",
    "for fold in folds_heating_normalized:\n",
    "    st=time.time()\n",
    "    dist=calculate_distances(fold[0],fold[2],fold[1])\n",
    "    et=time.time()\n",
    "    passed=et-st\n",
    "    print(\"For fold {} , prediction time = {} \".format(fnum,passed))\n",
    "    folds_heating_result_normalized.append(dist)\n",
    "    fnum+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3021c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-normalized Data Prediction...\n",
      "For fold 1 , prediction time = 0.724172830581665 \n",
      "For fold 2 , prediction time = 0.719172477722168 \n",
      "For fold 3 , prediction time = 0.7211592197418213 \n",
      "For fold 4 , prediction time = 0.7241582870483398 \n",
      "For fold 5 , prediction time = 0.7183687686920166 \n",
      "Non-normalized Data Prediction...\n",
      "For fold 1 , prediction time = 0.7201566696166992 \n",
      "For fold 2 , prediction time = 0.7176048755645752 \n",
      "For fold 3 , prediction time = 0.7188091278076172 \n",
      "For fold 4 , prediction time = 0.7184183597564697 \n",
      "For fold 5 , prediction time = 0.7180113792419434 \n"
     ]
    }
   ],
   "source": [
    "#calculating distance arrays for Cooling Load\n",
    "folds_cooling_result=[]\n",
    "fnum=1\n",
    "print(\"Non-normalized Data Prediction...\")\n",
    "for fold in folds_cooling:\n",
    "    st=time.time()\n",
    "    dist=calculate_distances(fold[0],fold[2],fold[1])\n",
    "    et=time.time()\n",
    "    passed=et-st\n",
    "    print(\"For fold {} , prediction time = {} \".format(fnum,passed))\n",
    "    folds_cooling_result.append(dist)\n",
    "    fnum+=1\n",
    "\n",
    "folds_cooling_result_normalized=[]\n",
    "fnum=1\n",
    "print(\"Non-normalized Data Prediction...\")\n",
    "for fold in folds_cooling_normalized:\n",
    "    st=time.time()\n",
    "    dist=calculate_distances(fold[0],fold[2],fold[1])\n",
    "    et=time.time()\n",
    "    passed=et-st\n",
    "    print(\"For fold {} , prediction time = {} \".format(fnum,passed))\n",
    "    folds_cooling_result_normalized.append(dist)\n",
    "    fnum+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ecc3a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that returns average of MAE values for each k value\n",
    "def get_Avrgs_For_Mae(arr,n):\n",
    "    res=[]\n",
    "    for i in range(5):\n",
    "        tmp=[0.0]*n\n",
    "        for k in range(n):\n",
    "            for j in range(5): \n",
    "                tmp[k]+=arr[j][i][k]\n",
    "        res.append(tmp)\n",
    "        \n",
    "    for i in range(5):\n",
    "        for j in range(n):\n",
    "            res[i][j]=\"MAE :%\"+str(round(res[i][j]/5,3))\n",
    "       \n",
    "    return [i[0] for i in res], [i[1] for i in res]\n",
    "\n",
    "#processing KNN for each k value and each fold \n",
    "#this function simply returns pandas Dataframe of MAE metrics table\n",
    "#for both normal and weighted KNN\n",
    "def get_KNN_Table_pt2(fold_result,folds):\n",
    "    kArray=[1,3,5,7,9]\n",
    "    fnum=1\n",
    "    avrgArray=[]\n",
    "    resNormal=[]\n",
    "    resWeighted=[]\n",
    "    for dists in fold_result:\n",
    "        tmp=[]\n",
    "        tmpN=[]\n",
    "        tmpW=[]\n",
    "        for k in kArray:\n",
    "            predsNormal=kNN_for_Regression(dists,k)\n",
    "            predsWeighted=kNN_for_Regression(dists,k,kNNType=\"Weighted\")\n",
    "          \n",
    "            maeNormal=mae(predsNormal,folds[fnum-1][3])\n",
    "            maeWeighted=mae(predsWeighted,folds[fnum-1][3])\n",
    "            tmp.append([maeNormal,maeWeighted])\n",
    "            tmpN.append(\"MAE: %\"+str(round(maeNormal,3)))\n",
    "            tmpW.append(\"MAE: %\"+str(round(maeWeighted,3)))\n",
    "        \n",
    "        avrgArray.append(tmp)\n",
    "        fnum+=1\n",
    "        resNormal.append(tmpN)\n",
    "        resWeighted.append(tmpW)\n",
    "    avrN,avrW=get_Avrgs_For_Mae(avrgArray,2)\n",
    "    resNormal.append(avrN)\n",
    "    resWeighted.append(avrW)\n",
    "    \n",
    "    #normal KNN Results as Dataframe\n",
    "    df1=pd.DataFrame(resNormal,index=[\"Fold 1\",\"Fold 2\",\"Fold 3\",\"Fold 4\",\"Fold 5\",\"Average Of The Folds\"],\n",
    "                       columns=[\"k=1\",\"k=3\",\"k=5\",\"k=7\",\"k=9\"])\n",
    "    \n",
    "    #weighted KNN Results as Dataframe\n",
    "    df2=pd.DataFrame(resWeighted,index=[\"Fold 1\",\"Fold 2\",\"Fold 3\",\"Fold 4\",\"Fold 5\",\"Average Of The Folds\"],\n",
    "                       columns=[\"k=1\",\"k=3\",\"k=5\",\"k=7\",\"k=9\"])\n",
    "    return df1,df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd167054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN processing for each combinations\n",
    "dt_heating_normal,dt_heating_weighted=get_KNN_Table_pt2(folds_heating_result,folds_heating)\n",
    "\n",
    "normalized_heating_normal, normalized_heating_weighted = get_KNN_Table_pt2(folds_heating_result_normalized,folds_heating_normalized)\n",
    "\n",
    "dt_cooling_normal,dt_cooling_weighted=get_KNN_Table_pt2(folds_cooling_result,folds_cooling)\n",
    "\n",
    "normalized_cooling_normal, normalized_cooling_weighted = get_KNN_Table_pt2(folds_cooling_result_normalized,folds_cooling_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#printing Heating Load KNN results for report as markdown table\n",
    "\"\"\"\n",
    "print(\"Table of Heating Load For Non-normalized and Non-Weighted Data\\n\")\n",
    "print(dt_heating_normal.to_markdown()+\"\\n\")\n",
    "\n",
    "print(\"Table of Heating Load For Non-normalized and Weighted Data\\n\")\n",
    "print(dt_heating_weighted.to_markdown()+\"\\n\")\n",
    "\n",
    "print(\"Table of Heating Load For Normalized and Non-Weighted Data\\n\")\n",
    "print(normalized_heating_normal.to_markdown()+\"\\n\")\n",
    "\n",
    "print(\"Table of Heating Load For Normalized and Weighted Data\\n\")\n",
    "print(normalized_heating_weighted.to_markdown()+\"\\n\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing Cooling Load KNN results for report as markdown table\n",
    "\n",
    "\"\"\"\n",
    "print(\"Table of Cooling Load For Non-normalized and Non-Weighted Data\\n\")\n",
    "print(dt_cooling_normal.to_markdown()+\"\\n\")\n",
    "\n",
    "print(\"Table of Cooling Load For Non-normalized and Weighted Data\\n\")\n",
    "print(dt_cooling_weighted.to_markdown()+\"\\n\")\n",
    "\n",
    "print(\"Table of Cooling Load For Normalized and Non-Weighted Data\\n\")\n",
    "print(normalized_cooling_normal.to_markdown()+\"\\n\")\n",
    "\n",
    "print(\"Table of Cooling Load For Normalized and Weighted Data\\n\")\n",
    "print(normalized_cooling_weighted.to_markdown()+\"\\n\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d50c2c5",
   "metadata": {},
   "source": [
    "<h1 style=\"text-transform: uppercase;\n",
    "           font-size:40px;\n",
    "           color: #4d2c6d;\n",
    "            \">PART 2: Energy Efficiency Estimation from Data</h1>\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\"> Table of Heating Load For Non-normalized and Non-Weighted Data</h3>\n",
    "\n",
    "|                      | k=1         | k=3         | k=5         | k=7         | k=9         |\n",
    "|:---------------------|:------------|:------------|:------------|:------------|:------------|\n",
    "| Fold 1               | MAE: %2.667 | MAE: %1.832 | MAE: %1.7   | MAE: %1.905 | MAE: %2.099 |\n",
    "| Fold 2               | MAE: %2.506 | MAE: %1.757 | MAE: %1.768 | MAE: %2.034 | MAE: %2.198 |\n",
    "| Fold 3               | MAE: %2.588 | MAE: %1.732 | MAE: %1.566 | MAE: %1.927 | MAE: %2.079 |\n",
    "| Fold 4               | MAE: %2.588 | MAE: %1.64  | MAE: %1.381 | MAE: %1.659 | MAE: %1.888 |\n",
    "| Fold 5               | MAE: %2.636 | MAE: %1.678 | MAE: %1.488 | MAE: %1.742 | MAE: %2.011 |\n",
    "| Average Of The Folds | MAE :%2.597 | MAE :%1.728 | MAE :%1.581 | MAE :%1.853 | MAE :%2.055 |\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table of Heating Load For Non-normalized and Weighted Data</h3>\n",
    "\n",
    "|                      | k=1         | k=3         | k=5         | k=7         | k=9         |\n",
    "|:---------------------|:------------|:------------|:------------|:------------|:------------|\n",
    "| Fold 1               | MAE: %2.667 | MAE: %2.412 | MAE: %2.292 | MAE: %2.326 | MAE: %2.376 |\n",
    "| Fold 2               | MAE: %2.506 | MAE: %2.286 | MAE: %2.291 | MAE: %2.393 | MAE: %2.445 |\n",
    "| Fold 3               | MAE: %2.588 | MAE: %2.302 | MAE: %2.182 | MAE: %2.303 | MAE: %2.357 |\n",
    "| Fold 4               | MAE: %2.588 | MAE: %2.252 | MAE: %2.055 | MAE: %2.116 | MAE: %2.203 |\n",
    "| Fold 5               | MAE: %2.636 | MAE: %2.269 | MAE: %2.12  | MAE: %2.162 | MAE: %2.277 |\n",
    "| Average Of The Folds | MAE :%2.597 | MAE :%2.304 | MAE :%2.188 | MAE :%2.26  | MAE :%2.332 |\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table of Heating Load For Normalized and Non-Weighted Data</h3>\n",
    "\n",
    "|                      | k=1         | k=3         | k=5         | k=7         | k=9         |\n",
    "|:---------------------|:------------|:------------|:------------|:------------|:------------|\n",
    "| Fold 1               | MAE: %3.571 | MAE: %2.186 | MAE: %2.131 | MAE: %2.014 | MAE: %1.97  |\n",
    "| Fold 2               | MAE: %3.334 | MAE: %2.039 | MAE: %2.115 | MAE: %2.037 | MAE: %2.033 |\n",
    "| Fold 3               | MAE: %2.741 | MAE: %1.686 | MAE: %1.665 | MAE: %1.604 | MAE: %1.605 |\n",
    "| Fold 4               | MAE: %2.569 | MAE: %1.813 | MAE: %1.595 | MAE: %1.56  | MAE: %1.585 |\n",
    "| Fold 5               | MAE: %3.324 | MAE: %2.07  | MAE: %2.006 | MAE: %1.925 | MAE: %1.966 |\n",
    "| Average Of The Folds | MAE :%3.108 | MAE :%1.959 | MAE :%1.902 | MAE :%1.828 | MAE :%1.832 |\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table of Heating Load For Normalized and Weighted Data</h3>\n",
    "\n",
    "|                      | k=1         | k=3         | k=5         | k=7         | k=9         |\n",
    "|:---------------------|:------------|:------------|:------------|:------------|:------------|\n",
    "| Fold 1               | MAE: %3.571 | MAE: %2.151 | MAE: %2.11  | MAE: %2.02  | MAE: %1.972 |\n",
    "| Fold 2               | MAE: %3.334 | MAE: %1.993 | MAE: %2.066 | MAE: %2.003 | MAE: %2.002 |\n",
    "| Fold 3               | MAE: %2.741 | MAE: %1.675 | MAE: %1.638 | MAE: %1.595 | MAE: %1.581 |\n",
    "| Fold 4               | MAE: %2.569 | MAE: %1.748 | MAE: %1.579 | MAE: %1.54  | MAE: %1.539 |\n",
    "| Fold 5               | MAE: %3.324 | MAE: %2.021 | MAE: %1.969 | MAE: %1.919 | MAE: %1.931 |\n",
    "| Average Of The Folds | MAE :%3.108 | MAE :%1.917 | MAE :%1.873 | MAE :%1.815 | MAE :%1.805 |\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table of Cooling Load For Non-normalized and Non-Weighted Data</h3>\n",
    "\n",
    "|                      | k=1         | k=3         | k=5         | k=7         | k=9         |\n",
    "|:---------------------|:------------|:------------|:------------|:------------|:------------|\n",
    "| Fold 1               | MAE: %2.201 | MAE: %1.323 | MAE: %1.418 | MAE: %1.588 | MAE: %1.714 |\n",
    "| Fold 2               | MAE: %2.16  | MAE: %1.487 | MAE: %1.496 | MAE: %1.707 | MAE: %1.834 |\n",
    "| Fold 3               | MAE: %2.257 | MAE: %1.522 | MAE: %1.4   | MAE: %1.658 | MAE: %1.829 |\n",
    "| Fold 4               | MAE: %2.071 | MAE: %1.571 | MAE: %1.443 | MAE: %1.751 | MAE: %1.953 |\n",
    "| Fold 5               | MAE: %2.125 | MAE: %1.533 | MAE: %1.329 | MAE: %1.557 | MAE: %1.766 |\n",
    "| Average Of The Folds | MAE :%2.163 | MAE :%1.488 | MAE :%1.417 | MAE :%1.652 | MAE :%1.819 |\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table of Cooling Load For Non-normalized and Weighted Data</h3>\n",
    "\n",
    "|                      | k=1         | k=3         | k=5         | k=7         | k=9         |\n",
    "|:---------------------|:------------|:------------|:------------|:------------|:------------|\n",
    "| Fold 1               | MAE: %2.201 | MAE: %1.842 | MAE: %1.738 | MAE: %1.741 | MAE: %1.785 |\n",
    "| Fold 2               | MAE: %2.16  | MAE: %1.779 | MAE: %1.76  | MAE: %1.799 | MAE: %1.859 |\n",
    "| Fold 3               | MAE: %2.257 | MAE: %1.939 | MAE: %1.803 | MAE: %1.871 | MAE: %1.931 |\n",
    "| Fold 4               | MAE: %2.071 | MAE: %1.864 | MAE: %1.771 | MAE: %1.878 | MAE: %1.98  |\n",
    "| Fold 5               | MAE: %2.125 | MAE: %1.816 | MAE: %1.678 | MAE: %1.737 | MAE: %1.812 |\n",
    "| Average Of The Folds | MAE :%2.163 | MAE :%1.848 | MAE :%1.75  | MAE :%1.805 | MAE :%1.873 |\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table of Cooling Load For Normalized and Non-Weighted Data</h3>\n",
    "\n",
    "|                      | k=1         | k=3         | k=5         | k=7         | k=9         |\n",
    "|:---------------------|:------------|:------------|:------------|:------------|:------------|\n",
    "| Fold 1               | MAE: %3.811 | MAE: %2.355 | MAE: %2.334 | MAE: %2.208 | MAE: %2.191 |\n",
    "| Fold 2               | MAE: %3.77  | MAE: %2.444 | MAE: %2.497 | MAE: %2.334 | MAE: %2.279 |\n",
    "| Fold 3               | MAE: %2.911 | MAE: %1.933 | MAE: %1.911 | MAE: %1.837 | MAE: %1.786 |\n",
    "| Fold 4               | MAE: %2.834 | MAE: %1.918 | MAE: %1.874 | MAE: %1.783 | MAE: %1.816 |\n",
    "| Fold 5               | MAE: %3.613 | MAE: %2.223 | MAE: %2.158 | MAE: %1.994 | MAE: %1.99  |\n",
    "| Average Of The Folds | MAE :%3.388 | MAE :%2.175 | MAE :%2.155 | MAE :%2.031 | MAE :%2.013 |\n",
    "\n",
    "<h3 style=\"text-align:center ;text-transform: uppercase;\n",
    "           color: #4d2c6d;\">Table of Cooling Load For Normalized and Weighted Data</h3>\n",
    "\n",
    "|                      | k=1         | k=3         | k=5         | k=7         | k=9         |\n",
    "|:---------------------|:------------|:------------|:------------|:------------|:------------|\n",
    "| Fold 1               | MAE: %3.811 | MAE: %2.354 | MAE: %2.337 | MAE: %2.237 | MAE: %2.215 |\n",
    "| Fold 2               | MAE: %3.77  | MAE: %2.427 | MAE: %2.474 | MAE: %2.35  | MAE: %2.307 |\n",
    "| Fold 3               | MAE: %2.911 | MAE: %1.937 | MAE: %1.903 | MAE: %1.852 | MAE: %1.802 |\n",
    "| Fold 4               | MAE: %2.834 | MAE: %1.881 | MAE: %1.853 | MAE: %1.785 | MAE: %1.793 |\n",
    "| Fold 5               | MAE: %3.613 | MAE: %2.204 | MAE: %2.151 | MAE: %2.02  | MAE: %2.016 |\n",
    "| Average Of The Folds | MAE :%3.388 | MAE :%2.161 | MAE :%2.144 | MAE :%2.049 | MAE :%2.026 |\n",
    "\n",
    " \n",
    "<h1 style=\"color: #4d2c6d;\">Error Analysis for Regression </h1>\n",
    "<ul>\n",
    "  <li><p> There are two distinct ground-truth values which named \"Heating Load\" and \"Cooling Load\" in this regression problem. Number of training samples are significant factor for the accuracy of the model. Using fewer number of training samples affects accuracy of the model negatively. For both ground-truth values until a certain k-value mean absolute error decreases. However, if k-value keeps increasing mean absolute error increases. So, accuracy of the model and k-value are not proportional. Increasing the k-value may not be a solution all the time for better accuracy of the model. When we investigate the average folds results from the tables, we realize that normalization affects ground-truth values differently. For \"Heating Load\" ground-truth value, mean absolute error decreases when we use normalization but for \"Cooling Load\" ground-truth value, mean absolute error increases that means accuracy of the model decreases when we use normalization. However, if we use weighted KNN algorithm instead of normal KNN algorithm, accuracy of the model increases for both ground-truth values. </p>\n",
    "\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
